# -*- coding: utf-8 -*-
"""Vishnu prjct - Diabetes Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NR0LEXOnMoqL4E59PfCaBL1qqUTLBtmd

Importing the Dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import norm

"""#Data Load

Diabetes Dataset
"""

from google.colab import drive
drive.mount('/content/drive')

diab_dset = pd.read_csv('/content/drive/MyDrive/Project/Diabetes prediction/Datasets/diabetes.csv')

diab_dset.head(5)

"""# Data Preprocessing phase"""

diab_dset.shape

diab_dset.isnull().sum()

diab_dset.info()

"""# Separating Categorical and Numeric datas"""

diab_cate = diab_dset.select_dtypes(object)
diab_numer = diab_dset.select_dtypes(np.number)

diab_numer.head()

diab_cate.head()

"""#From the data set Taking only  categorical columns"""

gender = diab_dset['gender']
smokehis = diab_dset['smoking_history']

gender

smokehis

gender.unique()

smokehis.unique()

"""#Handling categorical data into help of Label Encoding"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
genderlabel = le.fit_transform(gender)
smokelabel = le.fit_transform(smokehis)

gender.unique()

"""*** Female  = 0 , Male = 1 and Other   = 2***"""

genderlabel

smokehis.unique()

"""**No-Info = 0**, **Current = 1**, **Ever = 2**, **Former
 =3 ** , Never = 4** , **and Notcurrent = 5**



"""

smokelabel

"""**Concatenate to the original data set**"""

diab_dset = diab_dset.drop('gender',axis= 'columns')
diab_dset['gender'] = genderlabel

diab_dset = diab_dset.drop('smoking_history',axis= 'columns')
diab_dset['smoking_history'] = smokelabel

diab_dset.head()

"""# **Rearranging Columns**"""

diab_dset = diab_dset[['gender','age','hypertension','heart_disease','smoking_history','bmi','HbA1c_level','blood_glucose_level','diabetes']]

"""# Checking data types"""

diab_dset.dtypes

"""# Age columns has Float type converting into INT"""

diab_dset['age'] = diab_dset['age'].astype(int)

diab_dset.dtypes

diab_dset.head()

"""# **Method for checking zero values present in columns and return count**"""

def zeroval(dfcol):
  count = 0
  for i in dfcol:
    if(i==0):
      count = count +1;
  return count

zeroval(diab_dset['HbA1c_level'])

zeroval(diab_dset['bmi'])

zeroval(diab_dset['blood_glucose_level'])

zeroval(diab_dset['age'])

"""# Handling Zero values in Age columns Help of KNN IMPUTER"""

from sklearn.impute import KNNImputer
imputer = KNNImputer(missing_values = 0,n_neighbors = 2)
age = diab_dset['age'].values.reshape(-1, 1)


age1 = imputer.fit_transform(age)
diab_dset['age'] = age1.astype(int)
## Calling zeroval check method
zeroval(diab_dset['age'])

diab_dset.head()

"""# **Exploratory Analysis (EDA)**

# Outlier Detection

Normal distribution
"""

mu = np.mean(diab_dset['blood_glucose_level']) # mean
stdev = np.std(diab_dset['blood_glucose_level']) # standard deviation

x_start = mu - 4*stdev
x_end = mu + 4*stdev
step = 0.01

x = np.arange(start=x_start, stop=x_end+step, step=step)
y = norm.pdf( x=x, loc=mu, scale=stdev )



fig, ax = plt.subplots( figsize=(10, 5),)

# plot: normal distribution
ax.plot( x, y, label="probability density" )

ax.fill_between( x, y, alpha=0.2, )
ax.vlines( x=mu, ymin=0, ymax=max(y), linewidths=1.0, label="mean: {:.1f}".format(mu) )
ax.legend( fontsize=6, loc="upper left", frameon=True )
print(stdev)

"""Z -Score method

Z = ((X - Mean) / Standard Deviation)
"""

outliers = []

def detect_outlier(data):
  threshold = 3
  mean = np.mean(data)
  std = np.std(data)

  for i in data:
    z_score  = (i - mean)/std
    if np.abs(z_score) > threshold :
      outliers.append(i);
      return outliers

detect_outlier(diab_dset['blood_glucose_level'])

"""# BOX PLOT using dentify outlier data"""

import seaborn as sns
sns.boxplot(data = diab_dset, x = 'diabetes', y = 'bmi');

Lower_bound = diab_dset['bmi'].mean() - 3 * diab_dset['bmi'].std()
Upper_bound = diab_dset['bmi'].mean() + 3 * diab_dset['bmi'].std()

"""**Handling Outlier data Capping and Flooring**"""

diab_dset['bmi'] = diab_dset['bmi'].clip(Lower_bound,Upper_bound)

print(Lower_bound)
print(Upper_bound)

sns.boxplot(data = diab_dset, x = 'bmi', y = 'diabetes',orient = 'h',whis = (0,100))

diab_dset.head()

diab_dset['age']

"""# **Histogram Plot**"""

plt.hist(diab_dset['age'],bins = 10,edgecolor = 'black',color = 'skyblue')
plt.xlabel('AGE')
plt.ylabel("Frequencies")
plt.title('Histogram Of Age')
plt.show()

plt.hist(diab_dset['bmi'],bins = 10,edgecolor = 'black',color = 'skyblue')
plt.xlabel('BMI')
plt.ylabel("Frequencies")
plt.title('Histogram Of BODY MASS INDEX (BMI)')
plt.show()

diab_dset.head()

plt.hist(diab_dset['HbA1c_level'],bins = 10,edgecolor = 'black',color = 'skyblue')
plt.xlabel('Haemoglobin')
plt.ylabel("Frequencies")
plt.title('Histogram Of Haemoglobin Level')
plt.show()

plt.hist(diab_dset['blood_glucose_level'],bins = 10,edgecolor = 'black',color = 'skyblue')
plt.xlabel('Blood Glucose Level')
plt.ylabel("Frequencies")
plt.title('Histogram Of Blood Glucose Level')
plt.show()

diab_dset.head()

diab_dset['smoking_history'].unique()

"""# Pie Chart"""

plt.figure(figsize=(8, 6))
diab_dset['smoking_history'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'lightgreen', 'lightcoral'])
plt.title('Pie Chart of Smoking history')
plt.show()

plt.figure(figsize=(8, 6))
diab_dset['hypertension'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'lightgreen', 'lightcoral'])
plt.title('Pie Chart of HyperTension')
plt.show()

plt.figure(figsize=(8, 6))
diab_dset['heart_disease'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'lightgreen', 'lightcoral'])
plt.title('Pie Chart of HeartPatient')
plt.show()

plt.figure(figsize=(8, 6))
diab_dset['gender'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'lightgreen', 'lightcoral'])
plt.title('Pie Chart of Gender')
plt.show()

"""# **Gender attribute 0 -> Female  1-> Male 2 -> Others**

"""

diab_dset['gender'].value_counts()

"""**Replacing Others to Null values**





"""

diab_dset['gender'].replace(2,np.nan,inplace = True)

diab_dset['gender'].isnull().any()

diab_dset['gender'].value_counts()

"""**Handling null values into KNN imputer**"""

from sklearn.impute import KNNImputer
imputer = KNNImputer(missing_values = np.nan,n_neighbors = 2)
gen = diab_dset['gender'].values.reshape(-1, 1)


gen1 = imputer.fit_transform(gen)
diab_dset['gender'] = gen1.astype(int)

diab_dset['gender'].isnull().any()

diab_dset['gender'].value_counts()

"""# Plotting pie chart in Gender Attribute"""

plt.figure(figsize=(8, 6))
diab_dset['gender'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'lightgreen', 'lightcoral'])
plt.title('Pie Chart of Gender')
plt.show()

"""# **Machine Learning Model building**

**separating the data and labels**
"""

X = diab_dset.drop(columns = 'diabetes', axis=1)
y = diab_dset['diabetes']

X.head()

y.shape

"""# Train test Split

"""

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state= 42)

"""# Machine Learning Models
**KNN ALgorithm**
"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train,y_train.ravel())

knn.score(X_test,y_test)

knn.score(X_train,y_train)

y_pred = knn.predict(X_test)

from sklearn.metrics import confusion_matrix
y_pred = knn.predict(X_test)
cm = confusion_matrix(y_test,y_pred)
cm

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_pred, labels=knn.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn.classes_)
disp.plot()
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

"""# Linear Regression Multiple Variables"""

from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X_train,y_train)

reg.coef_

reg.intercept_

reg.predict(X_test)

from sklearn.metrics import confusion_matrix
y_pred = reg.predict(X_test)
cm = confusion_matrix(y_test,(y_pred) > 0.5)
cm

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, (y_pred)>0.5)#, labels=reg.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)#, display_labels=reg.classes_)
disp.plot()
plt.show()

reg.score(X_test,y_test)

from sklearn.metrics import classification_report
y_pred = reg.predict(X_test)
print(classification_report(y_test,(y_pred) > 0.5))

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression
log = LogisticRegression()
log.fit(X_train,y_train)

log.predict(X_test)

log.score(X_test,y_test)

from sklearn.metrics import confusion_matrix
y_pred = log.predict(X_test)
cm = confusion_matrix(y_test,(y_pred) > 0.5)
cm

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, (y_pred)>0.5)#, labels=reg.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)#, display_labels=reg.classes_)
disp.plot()
plt.show()

from sklearn.metrics import classification_report
y_pred = log.predict(X_test)
print(classification_report(y_test,(y_pred) > 0.5))

"""# Support Vector Machine (SVM)"""

from sklearn.svm import SVC
model = SVC(C=10)
model.fit(X_train,y_train)

model.score(X_test,y_test)

from sklearn.metrics import confusion_matrix
y_pred = model.predict(X_test)
cm = confusion_matrix(y_test,(y_pred) > 0.5)
cm

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, (y_pred)>0.5)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

from sklearn.metrics import classification_report
y_pred = model.predict(X_test)
print(classification_report(y_test,(y_pred) > 0.5))

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)

from sklearn import metrics
predictions = dtree.predict(X_test)
print("Accuracy Score =", format(metrics.accuracy_score(y_test,predictions)))

from sklearn.metrics import confusion_matrix
y_pred = dtree.predict(X_test)
cm = confusion_matrix(y_test,y_pred)
cm

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, (y_pred)>0.5)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

from sklearn.metrics import classification_report
y_pred = dtree.predict(X_test)
print(classification_report(y_test,y_pred))

"""# Model Evaluation
**K - Fold validation**
"""

from sklearn.model_selection import KFold
kf = KFold(n_splits=3, shuffle=True, random_state=42)
kf

for train_index,test_index in kf.split([1,2,3,4,5,6,7,8,9]):
  print(train_index,test_index)

from sklearn.model_selection import StratifiedKFold
folds = StratifiedKFold(n_splits = 3)

def get_score(model,X_train,X_test,y_train,y_test):
  model.fit(X_train,y_train)
  return model.score(X_test,y_test)

scores_knn=[]
scores_Linreg = []
scores_logreg = []
scores_SVM = []
scores_dtree = []

X = diab_dset.drop('diabetes', axis=1).values
y = diab_dset['diabetes'].values

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    scores_knn.append(get_score(KNeighborsClassifier(n_neighbors = 3),X_train,X_test,y_train,y_test))
    scores_Linreg.append(get_score(LinearRegression(),X_train,X_test,y_train,y_test))
    scores_logreg.append(get_score(LogisticRegression(),X_train,X_test,y_train,y_test))
    scores_SVM.append(get_score(SVC(C=10),X_train,X_test,y_train,y_test))
    scores_dtree.append(get_score(DecisionTreeClassifier(),X_train,X_test,y_train,y_test))

scores_knn

print("Mean score of KNN is ",np.mean(scores_knn))

scores_Linreg

print("Mean score of Linear Regression is ",np.mean(scores_Linreg))

scores_logreg

print("Mean score of Logistic_Regression is ",np.mean(scores_logreg))

scores_SVM

print("Mean score of Support_Vector_Machine is ",np.mean(scores_SVM))

scores_dtree

print("Mean score of Decision_Tree_classifiear is ",np.mean(scores_dtree))

input_data = (1,48,1,0,1,36.12,6.8,140)

input_data_as_array = np.asarray(input_data)

input_data_reshaped = input_data_as_array.reshape(1,-1)
print(input_data_reshaped)

# # standardize the input data
# std_data = scaler.fit_transform(input_data_reshaped)
# min_data = minmax.fit_transform(input_data_reshaped)
# print(min_data)
# knn = KNeighborsClassifier(n_neighbors = 3)
# knn.fit(X_train,y_train.ravel())


# dtree = DecisionTreeClassifier()
# dtree.fit(X_train, y_train)

from sklearn.linear_model import LogisticRegression
log = LogisticRegression()
log.fit(X_train,y_train)
prediction = log.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person has diabetic')

"""Saving trained model into file"""

import joblib
#from sklearn.externals import joblib

joblib.dump(log,'model_joblib')

mj = joblib.load('model_joblib')

#input_data = (5,166,72,19,175,25.8,0.587,51)
input_data = (1,48,1,0,1,36.12,6.8,140)


# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = mj.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person has diabetic')

